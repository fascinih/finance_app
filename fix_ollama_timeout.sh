#!/bin/bash

# Script para corrigir problemas de timeout do Ollama
echo "üîß Corrigindo timeouts do Ollama..."

# Cores
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

log() {
    echo -e "${GREEN}[OLLAMA-TIMEOUT-FIX]${NC} $1"
}

info() {
    echo -e "${BLUE}[OLLAMA-TIMEOUT-FIX]${NC} $1"
}

# Verificar se estamos no diret√≥rio correto
if [ ! -f "streamlit_app.py" ]; then
    echo "‚ùå Execute no diret√≥rio da Finance App"
    exit 1
fi

# Fazer backup
cp streamlit_app.py streamlit_app.py.backup_timeout

log "Melhorando fun√ß√µes de timeout do Ollama..."

# Usar Python para corrigir as fun√ß√µes
python3 << 'EOF'
import re

# Ler arquivo
with open('streamlit_app.py', 'r') as f:
    content = f.read()

# Substituir fun√ß√£o test_ollama_connection por vers√£o melhorada
old_function = r'def test_ollama_connection\(host, model\):.*?except Exception as e:\s+return False, f"Erro: \{str\(e\)\}"'

new_function = '''def test_ollama_connection(host, model):
    """Testa conex√£o com Ollama com timeouts melhorados."""
    try:
        import requests
        import json
        
        # Primeiro, testar se Ollama est√° rodando (timeout curto)
        try:
            response = requests.get(f"{host}/api/version", timeout=3)
            if response.status_code != 200:
                return False, "Ollama n√£o est√° respondendo"
        except requests.exceptions.Timeout:
            return False, "Ollama n√£o est√° respondendo (timeout)"
        except requests.exceptions.ConnectionError:
            return False, "Ollama n√£o est√° rodando"
        
        # Verificar se o modelo existe (sem gerar texto)
        try:
            response = requests.get(f"{host}/api/tags", timeout=5)
            if response.status_code == 200:
                data = response.json()
                available_models = [m['name'] for m in data.get('models', [])]
                if model not in available_models:
                    return False, f"Modelo '{model}' n√£o encontrado. Dispon√≠veis: {', '.join(available_models[:3])}"
            else:
                return False, "N√£o foi poss√≠vel verificar modelos"
        except requests.exceptions.Timeout:
            return False, "Timeout ao verificar modelos"
        
        return True, f"Ollama funcionando. Modelo '{model}' dispon√≠vel"
            
    except Exception as e:
        return False, f"Erro: {str(e)}"'''

# Substituir usando regex com flag DOTALL
content = re.sub(old_function, new_function, content, flags=re.DOTALL)

# Substituir fun√ß√£o get_ollama_models por vers√£o melhorada
old_models_function = r'def get_ollama_models\(host\):.*?except Exception as e:\s+return False, \[\]'

new_models_function = '''def get_ollama_models(host):
    """Lista modelos dispon√≠veis no Ollama com timeout melhorado."""
    try:
        import requests
        
        response = requests.get(f"{host}/api/tags", timeout=8)
        if response.status_code == 200:
            data = response.json()
            models = []
            for model in data.get('models', []):
                name = model['name']
                size = model.get('size', 0)
                size_gb = size / (1024**3) if size > 0 else 0
                models.append(f"{name} ({size_gb:.1f}GB)" if size_gb > 0 else name)
            return True, models
        else:
            return False, []
            
    except requests.exceptions.Timeout:
        return False, ["Timeout ao buscar modelos"]
    except requests.exceptions.ConnectionError:
        return False, ["Ollama n√£o est√° rodando"]
    except Exception as e:
        return False, [f"Erro: {str(e)}"]'''

content = re.sub(old_models_function, new_models_function, content, flags=re.DOTALL)

# Adicionar fun√ß√£o de teste r√°pido melhorada
quick_test_function = '''
def quick_ollama_test(host, model):
    """Teste r√°pido do Ollama com prompt simples."""
    try:
        import requests
        
        # Prompt muito simples para teste r√°pido
        test_data = {
            "model": model,
            "prompt": "Responda apenas: OK",
            "stream": False,
            "options": {
                "num_predict": 5,  # M√°ximo 5 tokens
                "temperature": 0.1
            }
        }
        
        response = requests.post(f"{host}/api/generate", json=test_data, timeout=30)
        if response.status_code == 200:
            result = response.json()
            return True, result.get("response", "Sem resposta").strip()
        else:
            return False, f"Erro HTTP {response.status_code}"
            
    except requests.exceptions.Timeout:
        return False, "Timeout - modelo pode estar carregando"
    except requests.exceptions.ConnectionError:
        return False, "Conex√£o falhou"
    except Exception as e:
        return False, f"Erro: {str(e)}"

'''

# Adicionar a nova fun√ß√£o antes da fun√ß√£o show_settings
insert_pos = content.find('def show_settings():')
if insert_pos != -1:
    content = content[:insert_pos] + quick_test_function + '\n' + content[insert_pos:]

# Salvar arquivo
with open('streamlit_app.py', 'w') as f:
    f.write(content)

print("‚úÖ Fun√ß√µes de timeout melhoradas")
EOF

log "Atualizando interface para usar timeouts melhorados..."

# Atualizar a interface para usar a nova fun√ß√£o de teste r√°pido
python3 << 'EOF'
# Ler arquivo
with open('streamlit_app.py', 'r') as f:
    content = f.read()

# Substituir o bot√£o de teste r√°pido por vers√£o melhorada
old_test_button = '''        with col4:
            if st.button("üß™ Teste R√°pido"):
                with st.spinner("Testando modelo..."):
                    try:
                        import requests
                        test_data = {
                            "model": ollama_model,
                            "prompt": "Categorize esta transa√ß√£o: PIX Supermercado ABC 150.00",
                            "stream": False
                        }
                        response = requests.post(f"{ollama_host}/api/generate", json=test_data, timeout=15)
                        if response.status_code == 200:
                            result = response.json()
                            st.success("‚úÖ Teste bem-sucedido!")
                            st.write("**Resposta:**", result.get("response", "Sem resposta"))
                        else:
                            st.error("‚ùå Falha no teste")
                    except Exception as e:
                        st.error(f"‚ùå Erro: {str(e)}")'''

new_test_button = '''        with col4:
            if st.button("üß™ Teste R√°pido"):
                with st.spinner("Testando modelo (pode demorar se estiver carregando)..."):
                    success, message = quick_ollama_test(ollama_host, ollama_model)
                    if success:
                        st.success(f"‚úÖ Teste bem-sucedido!")
                        st.write(f"**Resposta:** {message}")
                    else:
                        st.error(f"‚ùå {message}")
                        if "timeout" in message.lower() or "carregando" in message.lower():
                            st.info("üí° **Dica:** O modelo pode estar sendo carregado pela primeira vez. Aguarde alguns minutos e tente novamente.")'''

content = content.replace(old_test_button, new_test_button)

# Melhorar o bot√£o de listar modelos
old_list_button = '''        with col2:
            if st.button("üìã Listar Modelos"):
                with st.spinner("Buscando modelos..."):
                    success, models = get_ollama_models(ollama_host)
                    if success and models:
                        st.success("Modelos dispon√≠veis:")
                        for model in models:
                            st.write(f"‚Ä¢ {model}")
                    else:
                        st.error("‚ùå N√£o foi poss√≠vel listar modelos")'''

new_list_button = '''        with col2:
            if st.button("üìã Listar Modelos"):
                with st.spinner("Buscando modelos..."):
                    success, models = get_ollama_models(ollama_host)
                    if success and models:
                        st.success("Modelos dispon√≠veis:")
                        for model in models:
                            st.write(f"‚Ä¢ {model}")
                    else:
                        if isinstance(models, list) and models:
                            st.error("‚ùå Problemas ao listar:")
                            for error in models:
                                st.write(f"‚Ä¢ {error}")
                        else:
                            st.error("‚ùå N√£o foi poss√≠vel listar modelos")'''

content = content.replace(old_list_button, new_list_button)

# Salvar arquivo
with open('streamlit_app.py', 'w') as f:
    f.write(content)

print("‚úÖ Interface atualizada com timeouts melhorados")
EOF

# Verificar sintaxe
python3 -m py_compile streamlit_app.py 2>/dev/null && log "‚úÖ Sintaxe Python v√°lida" || log "‚ö†Ô∏è Verificar sintaxe"

echo ""
echo "=================================================="
echo -e "${GREEN}‚úÖ Timeouts do Ollama corrigidos!${NC}"
echo ""
echo "Melhorias implementadas:"
echo "‚Ä¢ ‚è±Ô∏è Timeouts mais inteligentes (3s, 5s, 8s, 30s)"
echo "‚Ä¢ üîç Verifica√ß√£o de modelo antes de testar"
echo "‚Ä¢ üìã Lista de modelos com tamanhos"
echo "‚Ä¢ üß™ Teste r√°pido com prompt simples"
echo "‚Ä¢ üí° Dicas para problemas de timeout"
echo "‚Ä¢ ‚ö†Ô∏è Mensagens de erro mais claras"
echo ""
echo "Agora reinicie o Streamlit:"
echo "‚Ä¢ Ctrl+C para parar"
echo "‚Ä¢ ./start_simple.sh para reiniciar"
echo ""
echo "Os timeouts devem estar muito melhores!"
echo "=================================================="

